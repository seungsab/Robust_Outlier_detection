{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from numpy import linalg\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Define some hyperparameters***\n",
    "---\n",
    "$$\n",
    "    \\text{Hyperparamerters you should define}\n",
    "$$\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hyperparameter():\n",
    "    # Define filename of dataset\n",
    "    fn_load = 'J_Dataset_1101_0630_outlier_3sig'\n",
    "\n",
    "    # # of skip in sample (for downsampling)\n",
    "    n_skip = 10\n",
    "\n",
    "    # Set initial Training samples\n",
    "    IDX_INIT_MODEL = 20000\n",
    "    # IDX_INIT_MODEL = 10000\n",
    "\n",
    "    # Set k-nearest neighbors in KNN\n",
    "    k = 10\n",
    "\n",
    "    # Set distance metric for kNN\n",
    "    dist_metric = 'euclidean'\n",
    "\n",
    "    # Significance level for comformal anomaly detection\n",
    "    # alpha = 0.95 # 95%\n",
    "    alpha = 0.997 # 99.7%\n",
    "\n",
    "    # Define type of anomaly detection\n",
    "    col_interest = ['CG_1', 'CG_2', 'TT_1','TT_2'] # Caisson #1\n",
    "    # col_interest = ['CG_3', 'CG_4', 'TT_3','TT_4'] # Caisson #2\n",
    "    return fn_load, n_skip, IDX_INIT_MODEL, k, dist_metric, alpha, col_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_dataset(fn_load = 'J_Dataset_1101_0630_outlier_3sig',\n",
    "    col_interest = ['Time', 'CG_1', 'CG_2', 'TT_1', 'TT_2']):\n",
    "    # 1. Import experimental dataset\n",
    "        with open(fn_load + '.pickle', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        fn = data['fn']\n",
    "        damage_ind = data['damage_ind']\n",
    "        df1, df3 = data['data'][0], data['data'][1]\n",
    "\n",
    "        # 2. Set Dataset\n",
    "        if 0:\n",
    "            col_interest = ['Time', 'CG_1', 'CG_2', 'TT_1', 'TT_2']\n",
    "            df = df1[col_interest]\n",
    "            Label = df1.Label.values\n",
    "\n",
    "        else:\n",
    "            col_interest = ['Time', 'CG_3', 'CG_4', 'TT_3', 'TT_4']\n",
    "            df = df3[col_interest]\n",
    "            Label = df3.Label.values\n",
    "\n",
    "        X_all = df.values[:, 1:]\n",
    "        return X_all.astype(np.float64), Label, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Data Manager**\n",
    "A class to manage our experimental data set for recursive monitoring\n",
    "- Initial training set for initial baseline model\n",
    "- Update baseline model and manipulate training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():\n",
    "\n",
    "    def __init__(self, X, Y, df, IDX_INIT_MODEL = 20000, n_skip = 1):\n",
    "        # 1. Save data into class\n",
    "        self.X, self.Y, self.df = X, Y, df\n",
    "        \n",
    "        # 2. Reduce the sequence of dataset (too many samples)\n",
    "        # (Optional, determined by n_skip)\n",
    "        self.reduce_sequence_by_skip(n_skip)\n",
    "        IDX_INIT_MODEL = int(IDX_INIT_MODEL/n_skip)\n",
    "        self.IDX_INIT_MODEL = IDX_INIT_MODEL\n",
    "\n",
    "        # 3. Find damage index as # index of sample\n",
    "        damage_ind = []\n",
    "        for ind_label in np.unique(self.Y_all):\n",
    "            if ind_label != 0:\n",
    "                ind_damage = np.where(self.Y_all == ind_label)[0][0]\n",
    "                damage_ind.append(ind_damage)\n",
    "        \n",
    "        self.damage_ind = damage_ind\n",
    "\n",
    "        # 4. For Allocation of memory\n",
    "        SIZE_ALL = self.X_all.shape[0]\n",
    "        \n",
    "        self.Is_anomaly = np.zeros((SIZE_ALL, 1))\n",
    "        self.Threshold = np.zeros((SIZE_ALL, 1))\n",
    "\n",
    "        # 5. Set Initial Traininigset and Testset\n",
    "        self.Xtrain = self.X_all[0:IDX_INIT_MODEL,:]\n",
    "        self.Xtest = self.X_all[IDX_INIT_MODEL:,:]\n",
    "    \"\"\"\n",
    "        Reduce massive sample due to computational issues. \n",
    "        In reality, it doesn't matter becauses of online implemtation.\n",
    "        @params\n",
    "            n_skip: int\n",
    "                A # of samples for the skip\n",
    "            dat: np.ndarray\n",
    "                A mxn array with m samples with n features\n",
    "        @return\n",
    "            dat: Reduced # of samples int(m/n_skip)\n",
    "    \"\"\"\n",
    "    def reduce_sequence_by_skip(self, n_skip):\n",
    "        if self.X.ndim == 1:\n",
    "            self.X_all = self.X[::n_skip,]\n",
    "        else:\n",
    "            self.X_all = self.X[::n_skip, :]\n",
    "\n",
    "        self.Y_all = self.Y[::n_skip,]\n",
    "        self.df = self.df.iloc[::n_skip, :]\n",
    "\n",
    "    \"\"\"\n",
    "        Create a line plot of mxn data with label in y for legend creation and title\n",
    "        @params\n",
    "            x: np.ndarray\n",
    "                A mxn array with m samples with n features\n",
    "            y: np.ndarray\n",
    "                A m array of labels\n",
    "            title: str\n",
    "                The title of the scatter plot\n",
    "        @return\n",
    "            The generated plot in case you want to plot over it\n",
    "    \"\"\"\n",
    "    def plot_line_raw_data(self):\n",
    "        # Plot scatter plot (Time index vs. Label)\n",
    "        color_type_str = ['blue', 'orange', 'red']\n",
    "\n",
    "        plt.figure(figsize = (10, 3), dpi = 200)\n",
    "        for label_ind in np.unique(self.Y_all):\n",
    "            indice_ = np.where(self.Y_all == label_ind)\n",
    "            plt.plot(self.df.Time.iloc[indice_], self.Y_all[indice_], marker = '.', color = color_type_str[label_ind])\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Label')\n",
    "        plt.gca().set_yticks([0, label_ind])\n",
    "        plt.grid(linestyle = ':')\n",
    "        if 'CG_1' in self.df.columns:\n",
    "            struct_type = 'Caisson #1'\n",
    "        else:\n",
    "            struct_type = 'Caisson #3'\n",
    "\n",
    "        plt.title(struct_type)\n",
    "        plt.show()\n",
    "\n",
    "        for col_ind in range(self.X_all.shape[1]):\n",
    "            plt.figure(figsize = (10, 3), dpi = 200)\n",
    "            for label_ind in np.unique(self.Y_all):\n",
    "                row_ind = np.where(self.Y_all == label_ind)\n",
    "                plt.plot(self.df.Time.iloc[row_ind], self.X_all[row_ind, col_ind].reshape(-1, 1),\n",
    "                        marker = '.', color = color_type_str[label_ind])\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel(list(self.df.columns[1:])[col_ind])\n",
    "            plt.grid(linestyle = ':')\n",
    "            plt.title(struct_type)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3. K-Nearest Neighbor**\n",
    "A simple way to calculate a conformal predictor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tmp = KNearestNeighbors(k = 10)\n",
    "\n",
    "conformal_set = np.concatenate((Xtrain_scaled,Xnew_scaled))\n",
    "knn_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors():\n",
    "    \"\"\"\n",
    "        A simple real-valued function to compute the conformal scores\n",
    "        Each conformal score is the average k-nearest neighbors according to a specified metric\n",
    "        @params\n",
    "            k: int\n",
    "                Determines k nearest neighbors\n",
    "            metric: str\n",
    "                distance metric (see scipy's pdist function for valid metrics)\n",
    "    \"\"\"\n",
    "    def __init__(self,k,metric='euclidean'):\n",
    "        self._k = k\n",
    "        self._metric = metric\n",
    "\n",
    "    \"\"\"\n",
    "        Returns a pairwise distance matrix\n",
    "        @params\n",
    "            x: np.ndarray\n",
    "                An m x n array with m samples and n dimensions\n",
    "    \"\"\"\n",
    "    def get_pairwise_distance_matrix(self,x):\n",
    "        distances = pdist(x,self._metric)\n",
    "        distance_matrix = squareform(distances)\n",
    "        return distance_matrix\n",
    "\n",
    "    \"\"\"\n",
    "        Returns the mean pairwise distance between the k'th nearest neighbors\n",
    "        @params\n",
    "            x: np.ndarray\n",
    "                An m x n array with m samples and n dimensions\n",
    "    \"\"\"\n",
    "    def __call__(self,x):\n",
    "        distance_matrix = self.get_pairwise_distance_matrix(x)\n",
    "        distance_matrix = np.sort(distance_matrix,axis=1)\n",
    "        assert self._k +1 < distance_matrix.shape[1],\\\n",
    "            print('K must be less than the number of data points (k={},num_samples={})'.format(self._k +1,distance_matrix.shape[1]))\n",
    "        return np.mean(distance_matrix[:,1:self._k+1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4. Conformal Anomaly Detector (CAD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformalAnomalyDetector():\n",
    "    \"\"\"\n",
    "    Conformal Anomaly Detector Class\n",
    "    @params\n",
    "        ICM: class\n",
    "            An object whose call operation should produce an array of conformal scores\n",
    "        z: tuple (len==2)\n",
    "            Each element is an (x,y) pair of the training set for CAD\n",
    "        significance: float\n",
    "            The significance level (must be between 0 and 1 exclusive)\n",
    "    \"\"\"\n",
    "    def __init__ (self, ICM, x, y = None, significance=0.05):\n",
    "        self._ICM = ICM\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        assert significance > 0 and significance < 1, \\\n",
    "            print('Significance must be in range (0,1).')\n",
    "        self._significance = significance\n",
    "        \n",
    "    \"\"\"\n",
    "    Return true or false if the test example are an anomaly\n",
    "    @params\n",
    "        test: np.ndarray\n",
    "            A 1xn test example where m is the number of test examples and n is the number of dimensions\n",
    "    @return: bool\n",
    "        True if test input is anomaly and false otherwise \n",
    "    \"\"\"\n",
    "    def testIfAnomaly(self,test):\n",
    "        conformal_set = np.concatenate((self.x,test))\n",
    "        conformal_scores = self._ICM(conformal_set)\n",
    "        p = np.sum(conformal_scores >= conformal_scores[-1]) / (self.x.shape[0]+1)\n",
    "        return p < self._significance\n",
    "\n",
    "    \"\"\"\n",
    "    Return array of true or false if the test examples are an anomaly\n",
    "    @params\n",
    "        test: np.ndarray\n",
    "            A mxn test example where m is the number of test examples and n is the number of dimensions\n",
    "    @return: np.ndarray\n",
    "        An mx1 array of true if test input is anomaly and false otherwise \n",
    "    \"\"\" \n",
    "    def __call__(self,anomalies):\n",
    "        isAnomaly = [self.testIfAnomaly(np.expand_dims(anomalies[i],axis=0)) for i in range(anomalies.shape[0])]\n",
    "        return isAnomaly\n",
    "\n",
    "    \"\"\"\n",
    "    Change significance level (hyper-parameter)\n",
    "    @params\n",
    "        significance: float\n",
    "            The significance level (must be between 0 and 1 exclusive)\n",
    "    \"\"\" \n",
    "    def set_significance(self,significance):\n",
    "        assert significance > 0 and significance < 1, \\\n",
    "            print('Significance must be in range (0,1).')\n",
    "        self._significance = significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Main**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span >**K-neighbors should be most recent samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "# Load experimental data\n",
    "fn_load, n_skip, IDX_INIT_MODEL, k, dist_metric, alpha, col_interest = set_hyperparameter()\n",
    "X, Y, df = Load_dataset(fn_load, col_interest)\n",
    "\n",
    "# Generate DataManager Class\n",
    "dat = DataManager(X, Y, df, IDX_INIT_MODEL, n_skip)\n",
    "# dat.plot_line_raw_data()\n",
    "\n",
    "# Define KNN model\n",
    "k_nearest_neighbor = KNearestNeighbors(k=10) # Initialize the ICM that uses k-nearest neighbors(k=10)\n",
    "\n",
    "# Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(dat.Xtrain)\n",
    "conformal_predictor = ConformalAnomalyDetector(ICM=k_nearest_neighbor,x = dat.Xtrain) # initialize CAD\n",
    "\n",
    "Xnew = dat.Xtest[:100]\n",
    "significances = [0.025,0.05]\n",
    "for i in range(len(significances)):\n",
    "   significance = significances[i]\n",
    "   if Xnew.shape[0] == 1:\n",
    "      Xnew_scaled = scaler.transform(Xnew.reshape(1, -1))\n",
    "   else:\n",
    "      Xnew_scaled = scaler.transform(Xnew)\n",
    "   conformal_predictor.set_significance(significance) # change significance\n",
    "   isAnomaly = conformal_predictor(Xnew_scaled) # test if anomamlies according to current CAD\n",
    "   print(isAnomaly)\n",
    "   # title = 'CAD Visualization (significance level={})'.format(significance)\n",
    "   # data_generator.showAnomalies(anomalies,isAnomaly,block = i==len(significances)-1,title=title) # plot results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ConformalAnomalyDetector.set_significance of <__main__.ConformalAnomalyDetector object at 0x0000017639E8CE80>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conformal_predictor.set_significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     np.random.seed(123432) # set seed for reproducibility\n",
    "#     data_generator = DataGenerator(num_samples_per_class=25) # create 10 classes each with 25 samples\n",
    "#     k_nearest_neighbor = KNearestNeighbors(k=10) # Initialize the ICM that uses k-nearest neighbors(k=10)\n",
    "#     conformal_predictor = ConformalAnomalyDetector(ICM=k_nearest_neighbor,z=(data_generator.x,data_generator.y)) # initialize CAD\n",
    "#     anomalies = data_generator.create_anomaly(200) # Generate 200 anomalies\n",
    "\n",
    "#     significances = [0.025,0.05,0.25,0.5] # see how different significance levels affect results\n",
    "#     for i in range(len(significances)):\n",
    "#         significance = significances[i]\n",
    "#         conformal_predictor.set_significance(significance) # change significance\n",
    "#         isAnomaly = conformal_predictor(anomalies) # test if anomamlies according to current CAD\n",
    "#         title = 'CAD Visualization (significance level={})'.format(significance)\n",
    "#         data_generator.showAnomalies(anomalies,isAnomaly,block = i==len(significances)-1,title=title) # plot results\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Construct KNN model with given data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "\n",
    "#     np.random.seed(123432) # set seed for reproducibility\n",
    "#     data_generator = DataGenerator(num_samples_per_class=25) # create 10 classes each with 25 samples\n",
    "#     k_nearest_neighbor = KNearestNeighbors(k=k, metric=dist_metric) # Initialize the ICM that uses k-nearest neighbors(k=10)\n",
    "    \n",
    "    \n",
    "#     conformal_predictor = ConformalAnomalyDetector(ICM=k_nearest_neighbor,z=(data_generator.x,data_generator.y)) # initialize CAD\n",
    "#     anomalies = data_generator.create_anomaly(200) # Generate 200 anomalies\n",
    "\n",
    "#     significances = [0.025,0.05,0.25,0.5] # see how different significance levels affect results\n",
    "#     for i in range(len(significances)):\n",
    "#         significance = significances[i]\n",
    "#         conformal_predictor.set_significance(significance) # change significance\n",
    "#         isAnomaly = conformal_predictor(anomalies) # test if anomamlies according to current CAD\n",
    "#         title = 'CAD Visualization (significance level={})'.format(significance)\n",
    "#         data_generator.showAnomalies(anomalies,isAnomaly,block = i==len(significances)-1,title=title) # plot results\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robust_OD_port_infras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
